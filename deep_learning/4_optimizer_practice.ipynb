{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebba580",
   "metadata": {},
   "source": [
    "###### 4_optimizer_practice.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd306a",
   "metadata": {},
   "source": [
    "## 옵티마이저 (Optimizer)\n",
    "- 신경망이 학습하면서 '손실 함수의 결과값이 최소가 되도록' 가중치를 조정하는 알고리즘\n",
    "- 종류\n",
    "  1. Adam (Adaptive Moment Estimation)\n",
    "      - Momentum + RMSprop 조합\n",
    "      - 거의 모든 문제에서 좋은 성능\n",
    "      - 이미지, 시계열, 구조적 데이터 모두 가능\n",
    "  2. SGD (Stochastic Gradient Descent)\n",
    "      - 가장 기본적인 경사 하강법. 전체 데이터 대신 일부를 이용해 경사를 계산.\n",
    "      - 구현이 단순하지만 학습률 선택이 중요\n",
    "      - 학습용, 매우 단순한 모델에서 사용\n",
    "  3. RMSprop (Root Mean Square Propagation)\n",
    "      - 각 가중치마다 최근 변화량을 평균내어 학습률을 조정하는 방식\n",
    "      - RNN, LSTM 같은 순차 모델에서 매우 안정적\n",
    "      - 시계열, 자연어 처리, 손실이 많이 표현되는 데이터에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19323e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n",
      "* ----- adam ----- *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9618 - loss: 0.1234\n",
      " 결과 :: loss - 0.1234 / accuracy - 0.9618\n",
      "* ----- sgd ----- *\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.8926 - loss: 0.4023\n",
      " 결과 :: loss - 0.4023 / accuracy - 0.8926\n",
      "* ----- rmsprop ----- *\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9680 - loss: 0.1111\n",
      " 결과 :: loss - 0.1111 / accuracy - 0.9680\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 사용 -> 숫자 이미지\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "# * 데이터 준비\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#   - 전처리 (정규화, 인코딩)\n",
    "#     독립변수 데이터 -> 정규화 (0~255 -> 0~1)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "#     종속변수 데이터 -> 인코딩 (범주형 데이터 -> 0 ~ 1)\n",
    "#     0 ~ 9 숫자\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# 테스트 옵티마이저 목록\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "\n",
    "for opt in optimizers:\n",
    "  print(f'* ----- {opt} ----- *')\n",
    "\n",
    "  # * 모델 정의\n",
    "  model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "  ])\n",
    "  # 'softmax' : 전체 합이 1이 되도록 0 ~ 1 사이 값으로 바꿔줌\n",
    "  # Dense(128) 설정 이유?\n",
    "  # * 보통 32, 64, 128, 256, 512, ... 와 같이 2의 제곱 계열 숫자를 많이 씀\n",
    "  # * Flatten -> 784개 -> Dense(128) -> Dense(64) -> Dense(10)\n",
    "\n",
    "  # * 컴파일 : 옵티마이저, 손실함수, 결과 설정\n",
    "  model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # * 학습\n",
    "  model.fit(x_train, y_train, epochs=2, batch_size=128, verbose=0)\n",
    "  # * batch_size : 전체 데이터를 한 번에 학습하지 않고, 일정 개수만큼 끊어서 학습시키는 단위\n",
    "  #   => 전체 데이터를 한 번에 학습하면 메모리가 감당하기 어려울 수 있음\n",
    "  #   => 나누어 계산하면 안정적이고 빠름 (128, 256 값을 많이 사용함)\n",
    "  # [참고] 가중치 업데이트 횟수 : ( total_data_size / batch_size ) * epochs\n",
    "\n",
    "  # * 평가\n",
    "  loss, acc = model.evaluate(x_test, y_test)\n",
    "  print(f' 결과 :: loss - {loss:.4f} / accuracy - {acc:.4f}')\n",
    "  # => sgd가 다른 옵티마이저에 비해 좋지 않음! 손실값이 3배정도 차이남.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
